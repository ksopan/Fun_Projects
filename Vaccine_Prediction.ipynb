{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Vaccine Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coronavirus has impacted millions of lives all over the world, like so many, it has taken up a lot of my mental space and energy over the last year. I wanted to channel this energy into something that would have a positive impact in stopping the spread of this disease. In order to achieve herd immunity for this virus, experts estimate it would require 80 -90% of the population to be immune. This is a very high percentage, requiring an abundant supply of vaccines and a large percentage of the population ready and willing to get these vaccines. This is why I built a vaccine predictor, it allows us to predict those less likely to get a vaccine so that we can run targeted educational campaigns and public health outreach. Thus, increasing the percentage of the population who will get the vaccine. \n",
    "\n",
    "The data used to build this model came from a survey done by the CDC. The CDC provided an R script that I used to obtain an .Rdata file. To get this file into Python I installed pyreadr into my environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in .Rdata file \n",
    "result = pyreadr.read_r('NHFSPUF.Rdata')\n",
    "df = result['NHFSPUF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Preview of the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print columns in df\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains over 170 columns which correspond to features that describe the interview (language, timing etc.) as well as questions that were asked to the respondent. Not all of these columns are relevant to my end goal so I went through each one and did research to determine which ones to keep. Some questions were very similar so I picked only the most informative to keep. The CDC attached a codebook describing each column and what the values in it represent so I used this to aid in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check shape of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large number of rows tells us that we have enough data to be able to clean up null values and still be left with enough information to pull insights from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Choose to import only select columns, to maximize efficiency and eliminate redundancy\n",
    "df2 = df[['VACC_H1N1_F','VACC_SEAS_F','B_H1N1_LARGE', 'B_H1N1_FMASK','B_H1N1_RCONT','Q23','Q24', 'Q24_B','HQ23','HQ24','HQ24_B','AGEGRP','EDUCATION_COMP','INC_CAT1','INSURE','MARITAL','RENT_OWN_R','Q95','Q95_INDSTR','RACEETH4_I','SEX_I','MSA3_I','STATE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns so they communicate the contents of the column\n",
    "df2 = df2.rename(columns = {'VACC_H1N1_F':'h1n1_vaccine',\n",
    "                            'VACC_SEAS_F':'seasonal_vaccine',\n",
    "                            'B_H1N1_LARGE':'behavioral_large_groups',\n",
    "                            'B_H1N1_FMASK':'behavioral_f_mask',\n",
    "                            'B_H1N1_RCONT':'behavioral_out_home',\n",
    "                            'Q23':'opinion_flu_effective', \n",
    "                            'Q24':'opinion_flu_risk', \n",
    "                            'Q24_B':'opinion_sick_from_f_vacc',\n",
    "                            'HQ24':'opinion_h1n1_risk', \n",
    "                            'HQ23':'opinion_h1n1_effective', \n",
    "                            'HQ24_B':'opinion_sick_from_h1n1_vacc', \n",
    "                            'AGEGRP':'age_group',\n",
    "                            'EDUCATION_COMP':'education_level',\n",
    "                            'INC_CAT1':'household_income',\n",
    "                            'INSURE': 'health_insurance',\n",
    "                            'MARITAL':'marital_status',\n",
    "                            'RENT_OWN_R':'rent_or_own',\n",
    "                            'Q95':'work_status',\n",
    "                            'Q95_INDSTR': 'employment_industry',\n",
    "                            'RACEETH4_I': 'race', \n",
    "                            'SEX_I': 'sex',\n",
    "                            'MSA3_I': 'msa_status',\n",
    "                            'STATE':'state'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers for each question in the survey are in numeric form, the corresponding answer can be found in the codebook that was included with the survey. I will include this in the data dictionary below. As most of the data is ordinal, it makes sense to leave this in numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target variables:**\n",
    " - h1n1_vaccine:\n",
    "     - 0 - did not receive vaccine\n",
    "     - 1 - received vaccine\n",
    " - seasonal_vaccine:\n",
    "     - 0 - did not receive vaccine\n",
    "     - 1 - received vaccine\n",
    "\n",
    "**Behavioral Indicators:**\n",
    " - behavioral_large_groups: Have you reduced your time at large gatherings?\n",
    "     - 0 - no\n",
    "     - 1 - yes\n",
    " - behavioral_f_mask: Have you bought a face mask?\n",
    "     - 0 -no\n",
    "     - 1 -yes\n",
    " - behavioral_out_home: Have you reduced your contact with people outside your home?\n",
    "     - 0 -no\n",
    "     - 1 -yes\n",
    "     \n",
    "**Opinions:**\n",
    " - opinion_flu_effective: In your opinion, what is the effectiveness of the seasonal flu vaccine?\n",
    "     - 1 - Very effective\n",
    "     - 2 - Somewhat effective\n",
    "     - 3 - Not very effective\n",
    "     - 4 - Not at all effective\n",
    "     - 77 - Don't know\n",
    "     - 99 - Refused\n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    "\n",
    " - opinion_flu_risk: In your opinion, what is the risk of getting sick with the flu without the seasonal flu vaccine?\n",
    "     - 1 - Very high\n",
    "     - 2 - Somewhat high\n",
    "     - 3 - Somewhat low\n",
    "     - 4 - Very low\n",
    "     - 77 - Don't know\n",
    "     - 99 - Refused\n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    " \n",
    " - opinion_sick_from_f_vacc : Are you worried about getting sick from the flu vaccine?\n",
    "     - 1 - Very worried\n",
    "     - 2 - Somewhat worried\n",
    "     - 3 - Not very worried\n",
    "     - 4 - Not at all worried\n",
    "     - 77 - Don't know\n",
    "     - 99 - Missing \n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    "\n",
    "- opinion_h1n1_effective: In your opinion, what is the effectiveness of the H1N1 vaccine?\n",
    "     - 1 - Very effective\n",
    "     - 2 - Somewhat effective\n",
    "     - 3 - Not very effective\n",
    "     - 4 - Not at all effective\n",
    "     - 77 - Don't know\n",
    "     - 99 - Refused\n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    " \n",
    "- opinion_h1n1_risk: In your opinion, what is the risk of getting sick with H1N1 without the H1N1 vaccine?\n",
    "     - 1 - Very high\n",
    "     - 2 - Somewhat high\n",
    "     - 3 - Somewhat low\n",
    "     - 4 - Very low\n",
    "     - 77 - Don't know\n",
    "     - 99 - Refused\n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    "\n",
    "- opinion_sick_from_h1n1_vacc : Are you worried about getting sick from the H1N1 vaccine?\n",
    "     - 1 - Very worried\n",
    "     - 2 - Somewhat worried\n",
    "     - 3 - Not very worried\n",
    "     - 4 - Not at all worried\n",
    "     - 77 - Don't know\n",
    "     - 99 - Missing \n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    "\n",
    "**Demographic Data:**\n",
    "- age_group: \n",
    "    - 1 - 18-34 Years\n",
    "    - 2 -35-44 Years\n",
    "    - 3 -45-54 Years\n",
    "    - 4 -55-64 Years\n",
    "    - 5 -65+ Years\n",
    "\n",
    "- educational_level\n",
    "    - 1 - <12 Years\n",
    "    - 2 - 12 Years\n",
    "    - 3 - Some College\n",
    "    - 4 - College Graduate\n",
    "    \n",
    "- household_income\n",
    "    - 1 - <= 10,000\n",
    "    - 2 - 10,001 - 15,000\n",
    "    - 3 - 15,001 - 25,000\n",
    "    - 4 - 25,001 - 35,000\n",
    "    - 5 - 35,001 - 50,000\n",
    "    - 6 - 75,001 - 100,000\n",
    "    \n",
    "- marital_status\n",
    "    - 1 - Not Married\n",
    "    - 2 - Married\n",
    "    \n",
    "- rent_or_own\n",
    "    - 1 - own\n",
    "    - 2 - rent\n",
    "    \n",
    "- work_status\n",
    "    - 1 - Employed\n",
    "    - 2 - Unemployed\n",
    "    - 3 - Not in Labor Force\n",
    "    - 77 - Don't Know\n",
    "    - 99 - Refused\n",
    "\n",
    "Both 77 and 99 will be imputed with the mode, as these categories do not provide information\n",
    "\n",
    "- race\n",
    "    - 1 - Hispanic\n",
    "    - 2 - African American\n",
    "    - 3 - Caucasian\n",
    "    - 4 - Other or Multiple Races\n",
    "- sex \n",
    "    - 1 - Female\n",
    "    - 2 - Male\n",
    "    \n",
    "- msa_status\n",
    "\n",
    "    - 1 - principle city\n",
    "    - 2 - not principle city\n",
    "    - 3 - non-msa\n",
    "    \n",
    "- State \n",
    "     - States go in alphabetical order corresponding to 1 - 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the type of each variable\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the target variables to integers\n",
    "df2['h1n1_vaccine'] = df2['h1n1_vaccine'].astype(int)\n",
    "df2['seasonal_vaccine'] = df2['seasonal_vaccine'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the class balance\n",
    "(df2['h1n1_vaccine'] == 1).sum()/df2['h1n1_vaccine'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The herd immunity rate required to stop the transmission of the H1N1 influenza was 30-40%, so it makes sense that we have a low percentage of respondents receiving the vaccine. This class imbalance will make it more difficult for the model to learn the factors describing a person that received the vaccine. This class imbalance will require upsampling, enabling the model to achieve a higher precision and recall. We want to avoid a lazy model that will attempt to achieve a high accuracy score just by choosing 0 (no vaccine) everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null values\n",
    "df2['h1n1_vaccine'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check percentage of null values to see what should be done\n",
    "(df2['h1n1_vaccine'].isna().sum()/df2['h1n1_vaccine'].count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a very small percentage of null values, these will be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop all rows that are Nan\n",
    "df2 = df2.dropna(subset = ['h1n1_vaccine'], axis = 0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null values\n",
    "df2['seasonal_vaccine'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null values percentage\n",
    "((df2['seasonal_vaccine'].isna().sum())/df2['seasonal_vaccine'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these rows that are null values \n",
    "#Since this is the target variable, this should not be imputed\n",
    "df2 = df2.dropna(subset = ['seasonal_vaccine'], axis = 0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check the amount of null values in the df\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a similar amount of null values between behavioral_large_groups, behavioral_f_mask, behavioral_out_home, opinion_flu_effective, opionion_flu_risk, opinion_sick_from_f_vaccine, opinion_h1n1_effective, opinion_h1n1_risk, opinion_sick_from_h1n1_vaccine, and education_level. It would be beneficial to see if these null values are all in the same row, if so, we will drop these values as the row does not provide much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if there are a high percentage of null values between these rows\n",
    "df2[df2['behavioral_f_mask'].isna() & df2['behavioral_large_groups'].isna() & df2['behavioral_out_home'].isna() & df2['opinion_flu_effective'].isna() & df2['opinion_flu_risk'].isna() & df2['opinion_sick_from_f_vacc'].isna() & df2['opinion_h1n1_effective'].isna() & df2['opinion_h1n1_risk'].isna() & df2['opinion_sick_from_h1n1_vacc'].isna() & df2['education_level'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14,032 rows that have common null values between 10 columns, we will drop these rows since they are missing a lot of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of the 14032 rows found above that have a high percentage of null values\n",
    "indx = df2.index[df2['behavioral_f_mask'].isna() & df2['behavioral_large_groups'].isna() & df2['behavioral_out_home'].isna() & df2['opinion_flu_effective'].isna() & df2['opinion_flu_risk'].isna() & df2['opinion_sick_from_f_vacc'].isna() & df2['opinion_h1n1_effective'].isna() & df2['opinion_h1n1_risk'].isna() & df2['opinion_sick_from_h1n1_vacc'].isna() & df2['education_level'].isna()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these rows\n",
    "df2.drop(index = indx, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check shape to make sure these were dropped\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if there are null value commonalities between columns \n",
    "df2[df2['opinion_flu_effective'].isna() & df2['opinion_flu_risk'].isna() & df2['opinion_sick_from_f_vacc'].isna() & df2['opinion_h1n1_effective'].isna() & df2['opinion_h1n1_risk'].isna() & df2['opinion_sick_from_h1n1_vacc'].isna() & df2['education_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the values checked above, in a list\n",
    "indx = df2.index[df2['opinion_flu_effective'].isna() & df2['opinion_flu_risk'].isna() & df2['opinion_sick_from_f_vacc'].isna() & df2['opinion_h1n1_effective'].isna() & df2['opinion_h1n1_risk'].isna() & df2['opinion_sick_from_h1n1_vacc'].isna() & df2['education_level'].isna()].tolist()\n",
    "#Drop the index values that had rows with a high percentage of null values\n",
    "df2.drop(index = indx, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure these rows were dropped\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will look at columns which display similar behaviours. Intuitively, if someone answers yes to reducing their contacts outside their home, there is a high likelihood they also answered yes to reducing their time at large gatherings. We will check this below to see if a majority of the answers between the two questions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see what percentage of values between the columns are the same\n",
    "(df2['behavioral_large_groups'] == df2['behavioral_out_home']).value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% of repondents gave the same answer to the two questions above. This allows us to impute values between these two columns, if there is a null value in one, this can be filled with the value from the other.\n",
    "\n",
    "Below, we will check to see the percentage of rows where the two columns both have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check if behavioral large groups and behavioral out home have a high percentage of null values in the same row\n",
    "df2[df2['behavioral_large_groups'].isna() & df2['behavioral_out_home'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is not a high percentage of null values common between the two columns, we can apply the impute based on correlation technique described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the 'behavioral_large_groups' value into the 'behavioral_out_home' column wherever there is a null value\n",
    "f = lambda row: row['behavioral_large_groups'] if (str(row['behavioral_out_home'])=='nan') else row['behavioral_out_home']\n",
    "df2['behavioral_out_home'] = df2.apply(f, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the 'behavioral_out_home' value into the 'behavioral_large_groups' column wherever there is a null value\n",
    "f = lambda row: row['behavioral_out_home'] if (str(row['behavioral_large_groups'])=='nan') else row['behavioral_large_groups']\n",
    "df2['behavioral_large_groups'] = df2.apply(f, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check to see that it reduced the number of null values in the columns imputed above\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if behavioral large groups and behavioral face mask have a high percentage of null values in the same row\n",
    "df2[df2['behavioral_large_groups'].isna() & df2['behavioral_f_mask'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the 'behavioral_large_groups' value into the 'behavioral_face_mask' column wherever there is a null value\n",
    "f = lambda row: row['behavioral_large_groups'] if (str(row['behavioral_f_mask'])=='nan') else row['behavioral_f_mask']\n",
    "df2['behavioral_f_mask'] = df2.apply(f, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The employment_industry and health_insurance columns both have a high percentage of null values. Due to this high percentage, we will not bother with imputation as it will introduce a high degree of bias into the model. Below, we will drop all columns with a high percentage of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Require a column to have atleast 65% non-Nan values\n",
    "#Otherwise will drop column \n",
    "df2 = df2.dropna(axis=1, thresh=0.65*df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the columns have a low percentage of null values so we will impute the mode. The mode is the value that ocurs the most in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fill columns with the mode of each\n",
    "df2['work_status'] = df2['work_status'].fillna(df2['work_status'].mode()[0])\n",
    "df2['marital_status'] = df2['marital_status'].fillna(df2['marital_status'].mode()[0])\n",
    "df2['rent_or_own'] = df2['rent_or_own'].fillna(df2['rent_or_own'].mode()[0])\n",
    "df2['household_income'] = df2['household_income'].fillna(df2['household_income'].mode()[0])\n",
    "df2['education_level'] = df2['education_level'].fillna(df2['education_level'].mode()[0])\n",
    "df2['opinion_sick_from_h1n1_vacc'] = df2['opinion_sick_from_h1n1_vacc'].fillna(df2['opinion_sick_from_h1n1_vacc'].mode()[0])\n",
    "df2['opinion_h1n1_risk'] = df2['opinion_h1n1_risk'].fillna(df2['opinion_h1n1_risk'].mode()[0])\n",
    "df2['opinion_sick_from_f_vacc'] = df2['opinion_sick_from_f_vacc'].fillna(df2['opinion_sick_from_f_vacc'].mode()[0])\n",
    "df2['opinion_flu_risk'] = df2['opinion_flu_risk'].fillna(df2['opinion_flu_risk'].mode()[0])\n",
    "df2['opinion_flu_effective'] = df2['opinion_flu_effective'].fillna(df2['opinion_flu_effective'].mode()[0])\n",
    "df2['behavioral_out_home'] = df2['behavioral_out_home'].fillna(df2['behavioral_out_home'].mode()[0])\n",
    "df2['behavioral_f_mask'] = df2['behavioral_f_mask'].fillna(df2['behavioral_f_mask'].mode()[0])\n",
    "df2['behavioral_large_groups'] = df2['behavioral_large_groups'].fillna(df2['behavioral_large_groups'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure there are no null values left\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have answers labelled 'don't know' and 'refused', this does not contain useful information and will prevent us from being able to keep the numeric labels. Therefore, we will impute these columns with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list columns that contain 'dont know' and 'refused' \n",
    "list_columns = ('opinion_flu_effective', 'opinion_flu_risk', 'opinion_sick_from_f_vacc', 'opinion_h1n1_effective', 'opinion_h1n1_risk', 'opinion_sick_from_h1n1_vacc', 'rent_or_own', 'work_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#impute the mode\n",
    "for i in list_columns:\n",
    "    df2[i] = np.where(df2[i] == '77', df2[i].mode(), df2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#impute the mode\n",
    "for i in list_columns:\n",
    "    df2[i] = np.where(df2[i] == '99', df2[i].mode(), df2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to switch all columns which contain only two values into a 0 and 1 value. Currently, the marital status and sex column contains 1 and 2, so the 2 value wil, be switched to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch all values that are listed as 2 to a 0\n",
    "df2['marital_status'] = np.where(df2['marital_status'] == 2, 0, df2['marital_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Switch all values that are listed as 2 to a 0\n",
    "df2['sex'] = np.where(df2['sex'] == 2, 0, df2['sex'])\n",
    "df2['sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numeric values that correspond to states are not in order, there is no number three. This will be fixed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The states in the survey is missing the third value, fix so that this is in order\n",
    "for i in range(4, 57):\n",
    "    df2['state'] = np.where(df2['state'] == i, (i-1), df2['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to seperate the data into people who got the vaccine vs. did not get the vaccine. From this, I will be able to graph the ratio (% got vaccine/% no vaccine) across each factor to determine if there are any trends in the data. There needs to be enough variance in the data so that the model can pick up on any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dataframe of all respondents that received the H1N1 vaccine and another of those who did not\n",
    "yes_h1n1 = df2[df2['h1n1_vaccine']==1]\n",
    "no_h1n1 = df2[df2['h1n1_vaccine'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dataframe of all respondents that received the seasonal flu vaccine and another one of those who did not\n",
    "yes_seasonal = df2[df2['seasonal_vaccine']==1]\n",
    "no_seasonal = df2[df2['seasonal_vaccine'] ==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will make a function to calculate the ratio of people who received the vaccine over those that did not. This ratio will be calculated across all the possible answers within each category. This will be useful when doing EDA to examine if there are trends within the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the ratio of people who received the Seasonal Flu vaccine/ people who did not receive the vaccine\n",
    "def ratio_seasonal(variable):\n",
    "    y_seasonal = yes_seasonal.groupby(variable)['seasonal_vaccine'].count()\n",
    "    n_seasonal = no_seasonal.groupby(variable)['seasonal_vaccine'].count()\n",
    "    return y_seasonal/n_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the ratio of people who received the H1N1 vaccine/ people who did not receive the vaccine\n",
    "def ratio_h1n1(variable):\n",
    "    y_h1n1 = yes_h1n1.groupby(variable)['seasonal_vaccine'].count()\n",
    "    n_h1n1 = no_h1n1.groupby(variable)['seasonal_vaccine'].count()\n",
    "    return y_h1n1/n_h1n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioral Indicator - Reduced Time At Large Gatherings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert this column into int values\n",
    "df2['behavioral_large_groups'] = df2['behavioral_large_groups'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure this was converted\n",
    "df2['behavioral_large_groups'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('behavioral_large_groups').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Time At Large Gatherings')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('H1N1 Vacc. Ratio By Behavioral Indicator -Reduced Time At Large Gatherings')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('behavioral_large_groups').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Time At Large Gatherings')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('Flu Vacc. Ratio By Behavioral Indicator -Reduced Time At Large Gatherings')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioral Indicator - Bought A Face Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['behavioral_f_mask'] = df2['behavioral_f_mask'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('behavioral_f_mask').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Time At Large Gatherings')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('H1N1 Vacc. Ratio By Behavioral Indicator - Bought A Face Mask')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('behavioral_f_mask').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Time At Large Gatherings')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('Flu Vacc. Ratio By Behavioral Indicator - Bought A Face Mask')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioral Indicator - Reduced Contact Outside the Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['behavioral_out_home'] = df2['behavioral_out_home'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['behavioral_out_home'] = df2['behavioral_out_home'].astype(int)\n",
    "df2['behavioral_out_home'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('behavioral_out_home').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Contact Outside Home')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('H1N1 Vacc. Ratio By Behavioral Indicator - Reduced Contact Outside Home')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('behavioral_out_home').tolist())\n",
    "plt.xlabel('Behavioral Indicator - Reduced Contact Outside Home')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','No', 'Yes'))\n",
    "plt.title('Flu Vacc. Ratio By Behavioral Indicator - Reduced Contact Outside Home')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across each behavioral indicator we can see that there are trends showing if someone reduces their time at large gatherings, buys a face mask, and reduces their contact outside the home it is more likely they will receive a vaccine. This is the trend we would expect, as these behaviors show someone is taking these viruses seriously and is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Is the Seasonal Flu Vaccine Effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['opinion_flu_effective'] = df2['opinion_flu_effective'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('opinion_flu_effective').tolist())\n",
    "plt.xlabel('Opinion - Effectiveness of Seasonal Flu Vaccine')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Effective', 'Somewhat Effective','Not Very Effective','Not At All Effective'), rotation = 45)\n",
    "plt.title('Flu Vacc. Ratio By Opinion -Effectiveness of Seasonal Flu Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Is the H1N1 Vaccine Effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['opinion_h1n1_effective'] = df2['opinion_h1n1_effective'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('opinion_h1n1_effective').tolist())\n",
    "plt.xlabel('Opinion - Effectiveness of H1N1 Vaccine')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Effective', 'Somewhat Effective','Not Very Effective','Not At All Effective'), rotation = 45)\n",
    "plt.title('H1N1 Vacc. Ratio By Opinion -Effectiveness of H1N1 Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Risk of Getting Sick Without Seasonal Flu Vacinne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['opinion_flu_risk'] = df2['opinion_flu_risk'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('opinion_flu_risk').tolist())\n",
    "plt.xlabel('Opinion- Risk Of Getting Sick With Flu Without Vaccine')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very High', 'Somewhat High','Somewhat Low','Very Low'), rotation = 45)\n",
    "plt.title('Flu Vacc. Ratio By Opinion - Risk of Getting Sick With Flu Without Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Risk of Getting Sick Without H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int values\n",
    "df2['opinion_h1n1_risk'] = df2['opinion_h1n1_risk'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('opinion_h1n1_risk').tolist())\n",
    "plt.xlabel('Opinion - Risk Of Getting Sick With H1N1 Without The Vaccine')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very High', 'Somewhat High','Somewhat Low','Very Low'), rotation = 45)\n",
    "plt.title('H1N1 Vacc. Ratio By Opinion -Risk of Getting Sick With H1N1 Without Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Risk of Getting Sick From Flu Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['opinion_sick_from_f_vacc'] = df2['opinion_sick_from_f_vacc'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('opinion_sick_from_f_vacc').tolist())\n",
    "plt.xlabel('Opinion - Risk Of Getting Sick From Flu Vaccine')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Worried', 'Somewhat Worried','Not Very Worried','Not At All Worried'), rotation = 45)\n",
    "plt.title('Flu Vacc. Ratio By Opinion -Risk of Getting Sick From Flu Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('opinion_sick_from_f_vacc').tolist())\n",
    "plt.xlabel('Opinion -Risk Of Getting Sick From H1N1 Vaccine')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Worried', 'Somewhat Worried','Not Very Worried','Not At All Worried'), rotation = 45)\n",
    "plt.title('H1N1 Vacc. Ratio By Opinion -Risk of Getting Sick From H1N1 Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion - Risk of Getting Sick From H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['opinion_sick_from_h1n1_vacc'] = df2['opinion_sick_from_h1n1_vacc'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_h1n1('opinion_sick_from_h1n1_vacc').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('opinion_sick_from_h1n1_vacc').tolist())\n",
    "plt.xlabel('Opinion -Risk Of Getting Sick From Flu Vaccine')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Worried', 'Somewhat Worried','Not Very Worried','Not At All Worried'), rotation = 45)\n",
    "plt.title('Flu Vacc. Ratio By Opinion -Worry About Getting Sick From Flu Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('opinion_sick_from_h1n1_vacc').tolist())\n",
    "plt.xlabel('Opinion -Risk Of Getting Sick From H1N1 Vaccine')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Very Worried', 'Somewhat Worried','Not Very Worried','Not At All Worried'), rotation = 45)\n",
    "plt.title('H1N1 Vacc. Ratio By Opinion -Worry About Getting Sick From H1N1 Vaccine')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opinion questions above give a deeper insight into factors that play a role in people not receiving a vaccine. These factors can be used to inform the content of the educational campaigns. There are lower ratios for people who believe the vaccine is not very effective (both H1N1 and seasonal flu) and lower ratios for people who believe there's not a big risk of getting sick if they don't get the vaccine. It is also recognised that being worried about getting sick from the vaccine does not play a huge role in whether people get it or not. This is not what I would have expected, I thought it would have a bigger impact. Maybe this has something to do with psychology, if it makes them sick they think it's working. These factors should all inform what is addressed in the educational campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social and Economic Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4,5]) , height = ratio_h1n1('age_group').tolist())\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(6), ('0','18-34', '35-44','45-54','55-64','65+'))\n",
    "plt.title('H1N1 Vaccine Ratio By Age Group')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4,5]) , height = ratio_seasonal('age_group').tolist())\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(6), ('0','18-34', '35-44','45-54','55-64','65+'))\n",
    "plt.title('Flu Vaccine Ratio By Age Group')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age group proves to be a big indicator in who is likely to receive a flu vaccine. There is a large gap in the ratio of people receiving flu shots that are 18-34 years old compared to those 65+. This is likely due to the flu having a greater risk of complications and being more severe in the older population. Therefore, they are more proactive in protecting themselves against it. We will likely see a similar trend with COVID, like the flu, it disciminates against age. \n",
    "\n",
    "Examining the H1N1 vaccine ratio by age group, there is not as large of an effect. Influenza had the largest impact on the younger generation, 80% of deaths occured below the age of 65+. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('education_level').tolist())\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), (' ','<12 Years','12 Years', 'Some College','College Grad.'), rotation = 45)\n",
    "plt.title('H1N1 Vaccine Ratio By Education Level')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('education_level').tolist())\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), (' ','<12 Years','12 Years', 'Some College','College Grad.'), rotation = 45)\n",
    "plt.title('Flu Vaccine Ratio By Educational Level')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a trend among both graphs that show the more educated a person is the more likely they are to get a vaccine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4,5,6,7]) , height = ratio_h1n1('household_income').tolist())\n",
    "plt.xlabel('Household Income')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(8), (' ','<= $10,000',' 10,001- 15,000', '15,001- 25,000','25,001- 35,000','35,001- 50,000','50,001- 75,000','75,001- 100,000'), rotation = 45)\n",
    "plt.title('H1N1 Vaccine Ratio By Household Income')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4,5,6,7]) , height = ratio_seasonal('household_income').tolist())\n",
    "plt.xlabel('Household Income')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(8), (' ','<= $10,000',' 10,001- 15,000', '15,001- 25,000','25,001- 35,000','35,001- 50,000','50,001- 75,000','75,001- 100,000'), rotation = 45)\n",
    "plt.title('Flu Vaccine Ratio By Household Income')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in both graphs above, the higher the household income the higher the ratio of people receiving vaccines. This reinforces the trend we saw above in the education level category, typically income and education level go hand in hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to int\n",
    "df2['work_status'] = df2['work_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('marital_status').tolist())\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Ratio For H1N1 Vaccine')\n",
    "plt.xticks(np.arange(3), (' ','Not Married ','Married'))\n",
    "plt.title('Ratio By Marital Status')\n",
    "plt.margins(x = 0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('marital_status').tolist())\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Ratio For Seasonal Flu Vaccine')\n",
    "plt.xticks(np.arange(3), (' ','Not Married ','Married'))\n",
    "plt.title('Ratio By Marital Status')\n",
    "plt.margins(x = 0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the H1N1 vaccine and seasonal flu vaccine ratios show there is an increase in married couples getting vaccinated over singles. This could be related to age, as older people are more likely to receive a vaccine. Also, gender might play a role, females are more likely to get vaccinated than males, so wives could be encouraging their husbads to get vaccinated. Happy wife, happy life!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rent Or Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['rent_or_own'] = df2['rent_or_own'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['rent_or_own'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('rent_or_own').tolist())\n",
    "plt.xlabel('Rent or Own')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','Own', 'Rent'))\n",
    "plt.title('H1N1 Vaccine Ratio By Home Ownership')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('rent_or_own').tolist())\n",
    "plt.xlabel('Rent or Own')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','Own', 'Rent'))\n",
    "plt.title('Flu Vaccine Ratio By Home Ownership')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis above shows those who own a house get vaccinated at a higher ratio than those who rent or make other arrangements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['work_status'] = df2['work_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3]) , height = ratio_h1n1('work_status').tolist())\n",
    "plt.xlabel('Work Status')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(4), ('0','Employed', 'Unemployed', 'Not in Labor Force'))\n",
    "plt.title('H1N1 Vaccine Ratio By Work Status')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3]) , height = ratio_seasonal('work_status').tolist())\n",
    "plt.xlabel('Work Status')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(4), ('0','Employed', 'Unemployed', 'Not in Labor Force'))\n",
    "plt.title('Flu Vaccine Ratio By Work Status')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of people receiving flu vaccinations is highest for the population not in the labor force. This is likely due to the high percentage of seniors receiving the vaccine, most of whom would be retired. For the H1N1 vaccine, this trend holds true, although is less pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_h1n1('race').tolist())\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Hispanic', 'African-American','Caucasian','Other or Multiple Races'), rotation = 45)\n",
    "plt.title('H1N1 Vaccine Ratio By Race')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3,4]) , height = ratio_seasonal('race').tolist())\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(5), ('0','Hispanic', 'African-American','Caucasian','Other or Multiple Races'), rotation = 45)\n",
    "plt.title('Flu Vaccine Ratio By Race')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that Hispanic, Caucasian and other/multiple races received the vaccines at similar numbers. However, there is a much lower ratio among African-Americans, this lower number can be attributed to a number of reasons such as discrimination, safety concerns and barriers to access. In 1932-1973, the US Public Health Service conducted the Tuskegee Syphillis Experiment. They recruited African-American men to study the effects of untreated syphillis, they lied about the reason for the study and then witheld available treatments from these men. This provides just a glimpse of the abuse that African Americans have experienced from the US Health system and gives some insight into why there is less vaccine trust among this group. \n",
    "\n",
    "For the flu vaccine, people of colour receive the vaccine at a much lower ratio. This informs us that we need to focus the educational campaign on limiting barriers to access as well as focus on building the trust between the Government and these communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_h1n1('sex').tolist())\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','Female', 'Male'))\n",
    "plt.title('H1N1 Vaccine Ratio By Sex')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2]) , height = ratio_seasonal('sex').tolist())\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(3), ('0','Female', 'Male'))\n",
    "plt.title('Flu Vaccine Ratio By Sex')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios for males and females receiving the H1N1 vaccine are similar, with females having a slight lead, this lead grows larger for the flu vaccine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSA Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3]) , height = ratio_h1n1('msa_status').tolist())\n",
    "plt.xlabel('MSA Status')\n",
    "plt.ylabel('Ratio H1N1 Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(4), ('0','Principle City', 'Not Principle City','Non- MSA'), rotation = 45)\n",
    "plt.title('H1N1 Vacc. Ratio By Race')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = ([1,2,3]) , height = ratio_seasonal('msa_status').tolist())\n",
    "plt.xlabel('MSA Status')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "plt.xticks(np.arange(4), ('0','Principle City', 'Not Principle City','Non- MSA'), rotation = 45)\n",
    "plt.title('Flu Vaccine Ratio By Race')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there are no patterns or trends to be found in this data for either of the vaccines. This will not make it very useful for our model so it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is not much variance in the MSA variable, we will drop this column\n",
    "df2 = df2.drop(columns = 'msa_status', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = np.arange(1,52) , height = ratio_seasonal('state').tolist())\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Ratio Flu Vacc. (% vacc./ % no vacc.)')\n",
    "#plt.xticks(np.arange(56), rotation = 45)\n",
    "plt.title('Flu Vaccine Ratio By State')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(x = np.arange(1,52) , height = ratio_h1n1('state').tolist())\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Ratio H1n1 Vacc. (% vacc./ % no vacc.)')\n",
    "#plt.xticks(np.arange(56), rotation = 45)\n",
    "plt.title('H1N1 Vaccine Ratio By State')\n",
    "plt.margins(x = 0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state where someone lives proves to be a good indicator in whether someone will receive a vaccine. This could be due to a number of factors, including accessibility and demographic. Depending on the demographic in the state, one which has an older population, would likely have a higher ratio. Also some states put more funding into vaccines and increasing the accessibility of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm all variables are integers before modelling\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns within the data are binary or in a sequential order so will be left in their numeric forms. However, race and state need to be converted to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the target variables to integers\n",
    "df2['h1n1_vaccine'] = df2['h1n1_vaccine'].astype(int)\n",
    "df2['seasonal_vaccine'] = df2['seasonal_vaccine'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all columns which are not in a logical order of rank to dummy variables\n",
    "df_dummy = pd.get_dummies(data=df2, columns=['race','state'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set independent and dependent variables\n",
    "X = df_dummy.iloc[:, 2: df_dummy.shape[0]+1]\n",
    "y = df_dummy.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train test split, 80% remainder, 20% test\n",
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train test split to get the validation and trainsing set, 30% split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_remainder, y_remainder, test_size = 0.3, random_state = 2, stratify = y_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the validation set in a dataframe so I can visualize and work with it easier\n",
    "df_validation = pd.concat([y_validation, X_validation], axis = 1)\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, because there is a class imbalance between people who received the H1N1 vaccine and those who did not, the training data needs to be upsampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data into minority and majority classes\n",
    "train_df = pd.concat([y_train, X_train], axis = 1)\n",
    "minority = train_df[train_df.h1n1_vaccine == 1]\n",
    "majority = train_df[train_df.h1n1_vaccine ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsample the minority class so it is the same size as the majority\n",
    "from sklearn.utils import resample\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                replace = True,\n",
    "                                n_samples = majority.shape[0],\n",
    "                                random_state = 1\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Construct a dataframe with the upsampled data\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])\n",
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and Y upsampled training data\n",
    "X_train_us = df_upsampled.iloc[:,2:74]\n",
    "y_train_us = df_upsampled.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale upsampled X and Y variable data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train_us)\n",
    "X_train_us_ss = ss.transform(X_train_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multioutput Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end goal of my capstone is to build a model to predict whether a person will receive the COVID-19 vaccine. To do this, I will need to employ multi-task learning. Multi-task learning works by forcing the model to predict two target variables at once. In doing this, it introduces regularization into the model, preventing it from overfitting on one of the targets. By training my model to make a more general vaccine prediction, I will be able to use it to predict whether someone will receive the COVID-19 vaccine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model requires multilabel classification as it needs to predict two targets at the same time. The targets are not mutually exclusive, the respondent might have got both vaccines, one or none. A multiouput classifier essentially acts as a wrapper on a traditional model such as logistic regression or decision tree so it is able to predict both targets at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision tree or random forest, the data for logistic regression should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Define the model\n",
    "logreg = MultiOutputClassifier(estimator = LogisticRegression())\n",
    "#Fit\n",
    "logreg.fit(X_train_us_ss, y_train_us)\n",
    "#Predictions\n",
    "predictions = logreg.predict(X_validation)\n",
    "#Score\n",
    "print(logreg.score(X_train_us_ss, y_train_us))\n",
    "print(logreg.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to calculate the precision and recall\n",
    "def precision_recall(v, h):\n",
    "    precision = precision_score(v, h)\n",
    "    recall = recall_score(v, h)\n",
    "    return f'The precision is {precision} and recall is {recall}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import precision and recall packages\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#Calculate the precision and recall\n",
    "precision_recall(predictions[:,0], X_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the Seasonal Flu target variable\n",
    "precision_recall(predictions[:,1], X_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression with the multioutput classifier did not perform very well in either category of accuracy, precision, recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DTree = MultiOutputClassifier(estimator = DecisionTreeClassifier(max_depth = 8))\n",
    "DTree.fit(X_train_us, y_train_us)\n",
    "predictions = DTree.predict(X_validation)\n",
    "print(DTree.score(X_train_us, y_train_us))\n",
    "print(DTree.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the H1N1 target variable \n",
    "precision_recall(predictions[:,0], X_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the seasonal flu vaccine variable\n",
    "precision_recall(predictions[:,1], X_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RForest = MultiOutputClassifier(estimator = RandomForestClassifier(n_estimators = 100, max_depth = 13))\n",
    "RForest.fit(X_train_us, y_train_us)\n",
    "predictions = RForest.predict(X_validation)\n",
    "print(RForest.score(X_train_us, y_train_us))\n",
    "print(RForest.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the H1N1 target variable \n",
    "precision_recall(predictions[:,0], X_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the seasonal flu vaccine variable\n",
    "precision_recall(predictions[:,1], X_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the multiouput classifier are disappointing, the validation scores never reached above 50 and the precision and recall was very low for both targets. I also tried these models with different hyperparameters but the score did not reach above 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier chain is another multilabel classification tool which allows two target variables to be predicted using the same model. It works by predicting one of the targets and then incorporates that target into the independent variables to predict the second target. It also makes it possible to specify which order to predict them in, I chose to put the H1N1 target first as the class imbalance makes it more difficult for the model to pick up patterns on. It is beneficial for the model to use the seasonal flu vaccine variable for assistance in predicting this tougher target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define the model\n",
    "LogReg = ClassifierChain(LogisticRegression(C = 0.1), order = [1,0])\n",
    "#Fit the model on scaled data\n",
    "LogReg.fit(X_train_us_ss, y_train_us)\n",
    "precitions = LogReg.predict(X_validation)\n",
    "print(LogReg.score(X_train_us_ss, y_train_us))\n",
    "print(LogReg.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the H1N1 target variable \n",
    "precision_recall(predictions[:,0], X_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the seasonal flu vaccine variable\n",
    "precision_recall(predictions[:,1], X_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After playing around with different values for the regularization coefficient, I was unable to reach a higher accuracy or precision score using logistic regression. The multiouput and classifier chain yielded very similar results. The high precision and low recall scores for this model show the model is being very lazy when it comes to the H1N1 target, even after upsampling. It is predicting a lot of the values to be zero as that is the class that is the class giving the most information to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTree = ClassifierChain(DecisionTreeClassifier(max_depth = 8), order = [1,0])\n",
    "DTree.fit(X_train_us, y_train_us)\n",
    "predictions_DT = DTree.predict(X_validation)\n",
    "print(DTree.score(X_train_us, y_train_us))\n",
    "print(DTree.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the H1N1 target variable \n",
    "precision_recall(predictions[:,0], y_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the seasonal flu vaccine variable\n",
    "precision_recall(predictions[:,1], y_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the decision tree produced similar accuracy scores to the logistic regression, it performed better as a whole. The precision and accuracy scores for both target variables are much higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RForest = ClassifierChain(RandomForestClassifier(n_estimators = 100, max_depth = 13))\n",
    "RForest.fit(X_train_us, y_train_us)\n",
    "predictions = RForest.predict(X_validation)\n",
    "print(RForest.score(X_train_us, y_train_us))\n",
    "print(RForest.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the H1N1 target variable \n",
    "precision_recall(predictions[:,0], y_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the precision and recall for the seasonal flu vaccine variable\n",
    "precision_recall(predictions[:,1], y_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the classifier chain produced very similar results to the multioutput classifer so neither technique will be explored further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a number of iterations adjusting the number of hidden layers, nodes within these layers, and dropout rates I found the model shown below to be the most effective. I used the relu function for all layers except the last, the output layer uses the sigmoid function, this function does not require the targets to be mutually exclusive. I employed a dropout rate of 0.5 percent after each layer because it prevents overfitting, keeping the test and validation scores closer together.\n",
    "\n",
    "I tried both SGD and Adam as optimizers but the most optimal accuracy scores were found when using Adam. The loss function was chosen to be BinaryCrossentropy as I have targets that are 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Declare hidden layers\n",
    "model.add(layers.Dense(X_train_us.shape[1], activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "#Declare Output Layer\n",
    "model.add(layers.Dense(2, activation='sigmoid'))       \n",
    "\n",
    "#Compile the model\n",
    "model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(),  \n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train the model using 100 epochs\n",
    "history = model.fit(X_train_us, y_train_us, validation_data=(X_validation, y_validation), epochs= 100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model, determine the accuracies for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "train_accuracy = history.history[\"binary_accuracy\"][-1]\n",
    "result = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {result[1]:.4f}\") \n",
    "\n",
    "# Generate predictions\n",
    "predictions_NN = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_NN = np.where(predictions_NN>0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H1N1 precision and recall\n",
    "precision_recall(predictions_NN[:,0], y_validation.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seasonal flu vaccine precision and recall\n",
    "precision_recall(predictions_NN[:,1], y_validation.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy for train and validation sets \n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot loss for train and validation\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the train and validation accuracy scores and loss start to diverge at around 20-25 epochs. Therefore, we will choose 25 epochs to run for the final model. The precision for the H1N1 target is much higher than the recall for this model. Although I would like to optimize the precision, due to the applications of this model, it is still important to achieve more of a balance between the two. The thresholds effect on these variables will be explored below using the precision recall curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packagges\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "n_classes = 2\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "y_validation_curve = y_validation.copy().to_numpy()\n",
    "\n",
    "#Calculate the precision recall curve and average precision score\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i],_ = precision_recall_curve(y_validation_curve[:, i], predictions_NN[:, i])\n",
    "    average_precision[i] = average_precision_score(y_validation_curve[:, i], predictions_NN[:, i])\n",
    "    \n",
    "#Calculate the micro scores for the precision and recall and then average these across all classes\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_validation_curve.ravel(), predictions_NN.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_validation_curve, predictions_NN, average=\"micro\")\n",
    "\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the average precision score vs. recall\n",
    "plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision starts to significantly decrease after a threshold of 0.4. Therefore, to maximixe both of these scores, a threshold of 0.4 should be used. However, due to the applications of this model, we are focused on achieving a high precision. If the model is predicting someone will receive a vaccine, it is important this is right, otherwise this results in a missed opportunity for education and outreach. A lower recall score is still not desirable but has less of an impact, all it means is that a person who will receive the vaccine might still be marketed to. We will try and achieve a balance between maximizing both of these while still keeping precision high. Therefore, a threshold of 0.57 will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that was constructed above will be used as the final version, using the test set to score it instead of the validation set. Instead of using 100 epochs, 25 will be used. This is based on the insights from the accuracy and loss graphs shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run model using 25 epochs\n",
    "history = model.fit(X_train_us, y_train_us, validation_data=(X_test, y_test), epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "train_accuracy = history.history[\"binary_accuracy\"][-1]\n",
    "result = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\") \n",
    "\n",
    "# Generate predictions\n",
    "predictions_NN = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_NN = np.where(predictions_NN>0.57, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(predictions_NN[:,0], y_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(predictions_NN[:,1], y_test.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracy, precision and recall scores shown above we have created a great model. The accuracy scores are very close together for the train and test sets, meaning the model is not overfitting to the training set. The precision and recall scores are high for the seasonal flu vaccine target but still have room for improvement on the H1N1 vaccine. Steps to improve these scores will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for Improvement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to identify ways to improve the models precision on the H1N1 target. Due to the class imbalance, it has made it more difficult for the model to accuractely predict if someone received the vaccine. This will be explored further by plotting the correlation between the percent who received the vaccine and precision across each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(factor):\n",
    "    precision_list = []\n",
    "    count_h1n1 = []\n",
    "    count_flu = []\n",
    "    for i in range(X_test[factor].min(), X_test[factor].max() +1):\n",
    "        idx = X_test.index[X_test[factor] == i].tolist()\n",
    "        y_test_filter = y_test.loc[idx]\n",
    "        predictions = model.predict(X_test.loc[idx])\n",
    "        predictions = np.where(predictions>0.57, 1,0)\n",
    "        precision_list.append(precision_score(predictions[:,0], y_test_filter.iloc[:,0]))\n",
    "        count_h1n1.append((y_test_filter.iloc[:,0] ==1).sum()/y_test_filter.iloc[:,0].count())\n",
    "        count_flu.append((y_test_filter.iloc[:,1] ==1).sum()/y_test_filter.iloc[:,1].count())\n",
    "    plt.figure()\n",
    "    plot1 = plt.scatter(count_h1n1, precision_list, s = 60)\n",
    "    plt.xlabel('Percent Received H1N1 Vaccine')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Correlation Between Precision and Percentage Who Received Vaccine')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plot2 = plt.scatter(count_flu, precision_list, s = 60, color = 'darkorange')\n",
    "    plt.xlabel('Percent Received Seasonal Flu Vaccine')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Correlation Between Precision and Percentage Who Received Vaccine')\n",
    "    plt.show()\n",
    "    return plot1,plot2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the correlation for age group\n",
    "filtering('age_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the correlation for education level\n",
    "filtering('education_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the correaltion for household incomeb\n",
    "filtering('household_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plots above, we can see that there is a strong correlation between the percentage in each category that received the vaccine, and the precision of the model for that category. This shows that the class imbalance for the H1N1 target has a large impact on the precision of the model. If the amount of data is increased, the precision will follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be an integral part of reaching the high herd immunity rate needed to stop the spread of COVID-19. The exploratory data analysis gave an insight into who should be targeted with educational campaigns, public health outreach and increased accessibility to the vaccine. The ideal candidate would be a young, single, African-American male with less than a high school education. The exploratory data analysis also informed what information should be conveyed through these campaigns. It should include facts on why the vaccine is effective, the high risk of getting sick without a vaccine, and focus on building trust between the public health department and the African American community. In the past, there have been discriminatory and unjust practices that have led to this mistrust. The Tuskegee Syphillis Experiment was an abuse on the African American community where they recruited African American men to conduct an experiment on the effects of untreated syphilis. They lied about the purpose of this experiment and withheld treatments. This provides insight into why the vaccine adoption rate is so low among African Americans. It is important to understand this, and focus on addressing it in these campaigns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 72% accuracy score on the test data, the models performance exceeded expectations. There are almost an infinite amount of ways this neural network could be tuned even further by employing a grid search optimization on AWS, but this would cost a lot of time and money. The most effective way to improve the models performance would be to increase its ability to differentiate between someone receiving the H1N1 vaccine and someone not receiving it. After completing analysis on the precision across each group, there was found to be a direct correlation between percent who received the vaccine and precision. Due to the class imbalance, the model has a harder time being able to pick up on patterns that attribute to someone receiving the vaccine, as there is not a large amount of data to learn from. An addition of more data describing people who received the H1N1 vaccine would increase the accuracy and precision of the model. \n",
    "\n",
    "Another next step would be to compare this model to COVID-19 vaccine data once this is available. The seasonal flu and H1N1 influenza were chosen as the viruses to base this model off as they both share similarities to COVID. While a generalized model was made, and the test scores look promising, the final test of this model would be to see how well it generalizes to predicting COVID-19 vaccinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus Disease. (2020, 12 16). Retrieved from Government of Canada: https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19.html\n",
    "\n",
    "Goldhill, O. (2020, 07 30). American healthcare's racist history helped fuel a fear of vaccines. Retrieved from Quartz: https://qz.com/1886133/us-healthcares-racist-history-helped-fuel-a-fear-of-vaccines/\n",
    "\n",
    "UM Health Care. (2020). COVID-19 Vaccine Key to Reaching 'Herd Immunity'. Retrieved from Missouri UniversityHealth Care: https://www.muhealth.org/our-stories/covid-19-vaccine-key-reaching-herd-immunity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
